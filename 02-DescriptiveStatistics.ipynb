{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/shaneahmed/StatswithPython/blob/main/02-DescriptiveStatistics.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/shaneahmed/StatswithPython/blob/main/02-DescriptiveStatistics.ipynb\" target=\"_blank\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "### by Shan E Ahmed Raza\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Name: (Please write your name and ID here prior to submission)**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Credits to [Statistical Applications for the Behavioral and Social Sciences, 2nd Edition\n",
    "by K. Paul Nesselroade Jr, Laurence G. Grimm](https://www.wiley.com/en-us/Statistical+Applications+for+the+Behavioral+and+Social+Sciences%2C+2nd+Edition-p-9781119355397).\n",
    "\n",
    "In the [previous notebook](https://github.com/shaneahmed/StatswithPython/blob/main/01-Introduction%20to%20Python.ipynb) we discussed basic python syntax, data structures and objects. In this notebook, we will learn to import python modules and use them to perform descriptive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules in Python\n",
    "The definitions you made in the previous exercise for functions and variables are lost. You may want to use a handy function such as to calculate _the mean_ that you’ve written in several programs without copying its definition into each program. Python has a way to put definitions in a file and use them in a script or in an interactive instance of the interpreter. Such a file is called a module; definitions from a module can be imported into other modules or into the main module.\n",
    "\n",
    "A module is a file containing Python definitions and statements. The file name is the module name with the suffix .py\n",
    "appended. Within a module, the module’s name (as a string) is available as the value of the global variable __name__.\n",
    "In the previous notebook, you wrote a function to calculate fibonacci numbers you can save the code in a file named fibo.py in the current directory and import it in this notebook. Once the file is saved you can import the module in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fibo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You can run the fib function in fibo using `fibo.fib()` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibo.fib(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You can also import modules with a different name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fibo as fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib.fib(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You can import functions within a module directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibo import fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Module\n",
    "Python has some built-in modules such as `math`, `statistics` to perform basic statistical calculations. You can import statistics module using python `import`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(4) # sqrt function calculate square root of a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean([1, 2, 3, 4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Module in Python\n",
    "For more sophisticated functions you can install modules such as \"numpy\", \"scipy\", \"pandas\", using `pip` command or `conda` (if you are in anaconda environment). Let's install \"numpy\", \"scipy\", \"pandas\". \"!\" operator runs terminal commands in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    After installation we can import these modules directly. The examples below show mean calculation using numpy and pandas libraries. scipy will depreciating support for mean calculation and is proposing move to numpy mean calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy (numerical python) is usually imported as np in python codes\n",
    "import pandas as pd # pandas (Python Data Analysis Library) is usually imported in python as pd\n",
    "import scipy.stats as stats # SciPy is a collection of mathematical algorithms and convenience functions built on the NumPy \n",
    "                            # extension of Python. We are importing stats package from scipy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1, 2, 3, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas (Python Data Analysis Library) is usually imported in python as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame([1, 2, 3, 4, 4]) # pandas deals with data in data frame. we will learn about data frame in the following notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.mean()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution\n",
    "Let's consider the data in lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [15, 8, 20, 16, 12, 18, 14, 22, 17, 5,\n",
    "19, 15, 18, 29, 6, 13, 16, 19, 10, 24,\n",
    "15, 3, 26, 30, 13, 17, 7, 16, 23, 25,\n",
    "1, 15, 18, 14, 5, 27, 16, 20, 14, 6,\n",
    "24, 14, 20, 25, 21, 15, 17, 8, 23, 21,\n",
    "17, 14, 10, 13, 18, 16, 21, 9, 11, 22,\n",
    "15, 12, 9, 16, 20, 11, 13, 22, 17, 13,\n",
    "9, 22, 16, 12, 19, 17, 14, 10, 19, 18,\n",
    "11, 16, 12, 18, 13, 17, 15, 14, 15, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(data)[::-1] # Is the frequency distribution same as in the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data) # Identifies unique values in the data with f>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mean\n",
    "As calculated above mean can be calculated using `np.mean()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([5, 8, 10, 11, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    you can calculate mean of multiple columns in python using the same function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[15, 8, 20, 16, 12, 18, 14, 22, 17, 5],\n",
    "[19, 15, 18, 29, 6, 13, 16, 19, 10, 24]])\n",
    "\n",
    "data.to_numpy() # print the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    As data is in pandas data frame you can directly call the mean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Mean\n",
    "Weighted mean can be calculated using `np.average()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "School_A = [60, 40]\n",
    "School_B = [80, 70, 60]\n",
    "School_C = [75, 60, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = [np.mean(School_A), np.mean(School_B), np.mean(School_C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(mean_data, axis=0, weights=[2,3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Median\n",
    "You can calculate median using `np.median()` or `pd.DataFrame.median()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_odd_n = [40, 1, 4, 42, 6, 8, 43, 45, 47]\n",
    "data_even_n = [3, 9, 15, 16, 19, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(data_odd_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(data_even_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_odd_n = pd.DataFrame([40, 1, 4, 42, 6, 8, 43, 45, 47])\n",
    "data_even_n = pd.DataFrame([3, 9, 15, 16, 19, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_odd_n.median().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_even_n.median().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mode\n",
    "Mode can be calculated using `scipy.stats.mode` or `pd.DataFrame.mode()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [100, 101, 105, 105, 107, 108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mode().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [100, 101, 105, 106, 107, 108] # If all the members have equal frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mode().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range\n",
    "Range = X<sub>H</sub> - X<sub>L</sub>\n",
    "\n",
    "X<sub>H</sub> = Highest score in the distribution\n",
    "\n",
    "X<sub>L</sub> = Lowest score in the distribution\n",
    "\n",
    "Note: This is different from python [range function](https://docs.python.org/3/library/functions.html#func-range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [17, 44, 50, 23, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(data)-np.min(data) # np.max() calculates XH whereas np.min calculates XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use interquartile range function iqr in ``scipy.stats`` by setting the ``rng`` between 0 and 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.iqr(data, rng=[0, 100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Interquartile Range\n",
    "The above function can be used to calculate inter quartile range using default values for `rng`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.iqr(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([17, 44, 50, 23, 42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1, Q3 = data.quantile([0.25, 0.75], axis=0).to_numpy()\n",
    "Q3-Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-interquartile range\n",
    "siqr = iqr/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siqr = (Q3-Q1)/2\n",
    "print(siqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Deviation\n",
    "Let us consider the distributions in the lecture slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_a = [11, 12, 13, 14, 15, 16, 17]\n",
    "dist_b = [5, 8, 11, 14, 17, 20, 23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the distributions have $\\mu=14$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dist_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dist_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the definition of mean deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.absolute(dist_a-np.mean(dist_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.absolute(dist_b-np.mean(dist_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use `pd.series.mad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_a_series = pd.Series(dist_a)\n",
    "dist_b_series = pd.Series(dist_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_a_series.mad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_b_series.mad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "Variance is built into python `statistics` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.variance([3, 4, 6, 8, 9]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use `np.var()` to calculate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var([3, 4, 6, 8, 9], ddof=1) # By default numpy calculates population variance, by setting ddof=1 we are calculating\n",
    "                                # sample variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.stdev([3, 4, 6, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([3, 4, 6, 8, 9], ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "`pandas` provides built-in modules for correlation calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Generate 100 random numbers from a uniform distribution\n",
    "x = np.random.uniform(0,1,100)\n",
    "# Generate new set of numbers correlated with x\n",
    "df = pd.DataFrame(np.stack((x, x*2+1), axis=-1), columns=['x', 'x*2+1'])\n",
    "# Caluculate correlation between the variables\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new set of numbers negatively correlated with x\n",
    "df = pd.DataFrame(np.stack((x, -x*2+3), axis=-1), columns=['x', '-x*2+3'])\n",
    "# Caluculate correlation between the variables\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new set of random values from uniform distribution and find its correlation with x\n",
    "df = pd.DataFrame(np.stack((x, np.random.uniform(0.5,1.5,100)), axis=-1), columns=['x', '-x*2+3'])\n",
    "# Caluculate correlation between the variables\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kendall correlation\n",
    "df.corr('kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman Correlation\n",
    "df.corr('spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "That's the end of this notebook. \n",
    "We will discuss skewness, kurtosis and correlation between variables in the next notebook on visualisation. But before we leave there is something stats cannot measure.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/shaneahmed/StatswithPython/main/data/embedded_images/Stats_smile.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Run the following command to install seaborn package and download the `exercise` and `tips` dataset before starting the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "exercise = sns.load_dataset('exercise')\n",
    "exercise.head(20) # visualise the first 20 enteries in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head(20) # visualise the first 20 enteries in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get data from each column by using it's name e.g., exercise['pulse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise['pulse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Questions\n",
    "- In the tips data set which of the variables can be defined on nominal and ratio scale? [10]\n",
    "- Calcualte the frequency count, mean, median, mode, range, iqr, siqr of pulse rate in exercise data set [20]\n",
    "- Calcualte the frequency count, mean, median, mode, range, iqr, siqr, mean deviation, variance and standard deviation of total_bill and tip in tips data set. [40]\n",
    "- Calculate Pearson, Spearman and Kendall correlation between `total_bill` and `tip`. [30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
